{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcee792f-0dbf-4c06-920d-404c76c986d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales data loaded successfully.\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:4400\n",
      "Press CTRL+C to quit\n",
      "[2024-10-18 19:57:09,020] ERROR in app: Exception on /api/team_performance [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\fatima\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 1473, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\fatima\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 882, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\fatima\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 880, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\fatima\\anaconda3\\Lib\\site-packages\\flask\\app.py\", line 865, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\fatima\\AppData\\Local\\Temp\\ipykernel_4732\\2411938822.py\", line 81, in team_performance\n",
      "    feedback = analyze_sales_data(query)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\fatima\\AppData\\Local\\Temp\\ipykernel_4732\\2411938822.py\", line 20, in analyze_sales_data\n",
      "    inputs = tokenizer(query, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\fatima\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py\", line 3016, in __call__\n",
      "    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\fatima\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py\", line 3126, in _call_one\n",
      "    return self.encode_plus(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\fatima\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py\", line 3193, in encode_plus\n",
      "    padding_strategy, truncation_strategy, max_length, kwargs = self._get_padding_truncation_strategies(\n",
      "                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\fatima\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py\", line 2918, in _get_padding_truncation_strategies\n",
      "    raise ValueError(\n",
      "ValueError: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.\n",
      "127.0.0.1 - - [18/Oct/2024 19:57:09] \"GET /api/team_performance HTTP/1.1\" 500 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "\n",
    "os.environ['HF_HUB_DISABLE_SYMLINKS_WARNING'] = '1'\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load Hugging Face GPT model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
    "\n",
    "# Global sales data variable\n",
    "sales_data = None\n",
    "\n",
    "def analyze_sales_data(query):\n",
    "    \"\"\"Generate insights using the GPT model.\"\"\"\n",
    "    inputs = tokenizer(query, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    outputs = model.generate(inputs.input_ids, max_length=150)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "def load_sales_data():\n",
    "    \"\"\"Loads the sales performance data from 'sales_performance_data.csv'.\"\"\"\n",
    "    global sales_data\n",
    "    try:\n",
    "        sales_data = pd.read_csv('sales_performance_data.csv')\n",
    "        print(\"Sales data loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading sales data: {e}\")\n",
    "\n",
    "# Call this function at the start of the application\n",
    "load_sales_data()\n",
    "\n",
    "# Endpoint to upload data (optional if you want to allow re-uploading)\n",
    "@app.route('/api/upload_data', methods=['POST'])\n",
    "def upload_data():\n",
    "    global sales_data\n",
    "    file = request.files['file']\n",
    "    if file.filename.endswith('.csv'):\n",
    "        sales_data = pd.read_csv(file)\n",
    "    elif file.filename.endswith('.json'):\n",
    "        sales_data = pd.read_json(file)\n",
    "    else:\n",
    "        return jsonify({'error': 'Unsupported file format'}), 400\n",
    "    return jsonify({'message': 'Data uploaded successfully'}), 200\n",
    "\n",
    "# Individual sales representative performance analysis\n",
    "@app.route('/api/rep_performance', methods=['GET'])\n",
    "def rep_performance():\n",
    "    employee_id = request.args.get('rep_id')\n",
    "\n",
    "    if not employee_id:\n",
    "        return jsonify({\"error\": \"rep_id is required\"}), 400\n",
    "\n",
    "    if sales_data is None:\n",
    "        return jsonify({\"error\": \"No sales data available\"}), 404\n",
    "\n",
    "    # Check if 'employee_id' column exists\n",
    "    if 'employee_id' not in sales_data.columns:\n",
    "        return jsonify({\"error\": \"'employee_id' column not found in sales data\"}), 500\n",
    "\n",
    "    # Check if the employee_id is in the DataFrame\n",
    "    if employee_id not in sales_data['employee_id'].astype(str).unique():\n",
    "        return jsonify({\"error\": \"No data found for employee_id\"}), 404\n",
    "\n",
    "    # Fetch the performance data for the specific employee_id\n",
    "    performance_data = sales_data[sales_data['employee_id'].astype(str) == employee_id]\n",
    "    \n",
    "    # Return the performance data as a JSON response\n",
    "    return jsonify(performance_data.to_dict(orient='records')), 200\n",
    "\n",
    "# Team performance analysis\n",
    "@app.route('/api/team_performance', methods=['GET'])\n",
    "def team_performance():\n",
    "    if sales_data is None:\n",
    "        return jsonify({'error': 'No sales data available'}), 404\n",
    "\n",
    "    query = f\"Analyze the overall performance of the sales team based on the following data: {sales_data.to_json()}.\"\n",
    "    feedback = analyze_sales_data(query)\n",
    "    return jsonify({'team_feedback': feedback})\n",
    "\n",
    "# Sales performance trends and forecasting\n",
    "@app.route('/api/performance_trends', methods=['GET'])\n",
    "def performance_trends():\n",
    "    time_period = request.args.get('time_period')\n",
    "    \n",
    "    # Check if time_period is valid\n",
    "    if time_period not in ['monthly', 'quarterly']:\n",
    "        return jsonify({\"error\": \"Invalid time_period. Use 'monthly' or 'quarterly'.\"}), 400\n",
    "    \n",
    "    if sales_data is None:\n",
    "        return jsonify({'error': 'No sales data available'}), 404\n",
    "\n",
    "    query = f\"Analyze sales trends and provide forecasts based on {time_period} data: {sales_data.to_json()}.\"\n",
    "    feedback = analyze_sales_data(query)\n",
    "    return jsonify({'performance_trends': feedback})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(port=4400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fac98ac-2daa-4829-bccc-1cc7fe1b7ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:3500\n",
      "Press CTRL+C to quit\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, jsonify, request\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "data = pd.read_csv(\"sales_performance_data.csv\") \n",
    "\n",
    "# Initialize Hugging Face GPT \n",
    "model = pipeline('text-generation', model='gpt2')  \n",
    "\n",
    "\n",
    "# 1. Individual Sales Representative Performance Analysis\n",
    "\n",
    "@app.route('/api/rep_performance', methods=['GET'])\n",
    "def rep_performance():\n",
    "    rep_id = request.args.get('rep_id')\n",
    "    \n",
    "    # Find the sales representative data\n",
    "    rep_data = data[data['employee_id'] == int(rep_id)]\n",
    "    if rep_data.empty:\n",
    "        return jsonify({\"error\": \"Representative not found\"}), 404\n",
    "        \n",
    "    employee_name = rep_data['employee_name'].iloc[0]  # Get the name of the representative \n",
    "    # Perform analysis based on the data\n",
    "    total_leads = int(rep_data['lead_taken'].sum()) \n",
    "    total_revenue = float(rep_data['revenue_confirmed'].sum())  \n",
    "    \n",
    "    # Generate performance feedback using GPT \n",
    "    feedback_input = f\"{employee_name} has handled {total_leads} leads and generated ${total_revenue} in confirmed revenue. Provide feedback on this performance.\"\n",
    "    feedback = model(feedback_input, max_length=100, num_return_sequences=1, truncation=True)[0]['generated_text']\n",
    "    \n",
    "    return jsonify({\n",
    "        \"rep_id\": rep_id,\n",
    "        \"employee_name\": employee_name,\n",
    "        \"total_leads\": total_leads,\n",
    "        \"total_revenue\": total_revenue,\n",
    "        \"feedback\": feedback\n",
    "    })\n",
    "\n",
    "# 2. Overall Sales Team Performance Summary\n",
    "\n",
    "@app.route('/api/team_performance', methods=['GET'])\n",
    "def team_performance():\n",
    "    # Calculate overall team statistics\n",
    "    total_leads = int(data['lead_taken'].sum())  \n",
    "    total_revenue = float(data['revenue_confirmed'].sum()) \n",
    "    total_tours = int(data['tours_booked'].sum()) \n",
    "    \n",
    "    # Generate feedback on the team's overall performance\n",
    "    feedback_input = f\"The team has collectively taken {total_leads} leads, generated ${total_revenue} in revenue, and booked {total_tours} tours. Provide a summary of the team's performance.\"\n",
    "    team_feedback = model(feedback_input, max_length=100, num_return_sequences=1, truncation=True)[0]['generated_text']\n",
    "    \n",
    "    return jsonify({\n",
    "        \"total_leads\": total_leads,\n",
    "        \"total_revenue\": total_revenue,\n",
    "        \"total_tours\": total_tours,\n",
    "        \"feedback\": team_feedback\n",
    "    })\n",
    "\n",
    "# 3. Sales Performance Trends and Forecasting\n",
    "\n",
    "@app.route('/api/performance_trends', methods=['GET'])\n",
    "def performance_trends():\n",
    "    time_period = request.args.get('time_period')\n",
    "    data['dated'] = pd.to_datetime(data['dated'], errors='coerce') # Ensure 'dated' column is datetime\n",
    "    \n",
    "    # Analyze sales performance over the time period (e.g., monthly, quarterly)\n",
    "    if time_period == 'monthly':\n",
    "        period_data = data.groupby(data['dated'].dt.to_period('M')).sum(numeric_only=True)\n",
    "    elif time_period == 'quarterly':\n",
    "        period_data = data.groupby(data['dated'].dt.to_period('Q')).sum(numeric_only=True)\n",
    "    else:\n",
    "        return jsonify({\"error\": \"Invalid time period. Use 'monthly' or 'quarterly'.\"}), 400\n",
    "\n",
    "    # Generate trends and forecast feedback\n",
    "    leads_trend = period_data['lead_taken'].mean()\n",
    "    revenue_trend = period_data['revenue_confirmed'].mean()\n",
    "    forecast_input = f\"Based on the {time_period} data, the average leads are {leads_trend} and the average revenue is $ {revenue_trend}. Forecast the future performance.\"\n",
    "    forecast = model(forecast_input, max_length=100, num_return_sequences=1)[0]['generated_text']\n",
    "\n",
    "    return jsonify({\n",
    "        \"time_period\": time_period,\n",
    "        \"average_leads\": leads_trend,\n",
    "        \"average_revenue\": revenue_trend,\n",
    "        \"forecast\": forecast\n",
    "    })\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(port=3500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ba385e-63c5-4e19-bafa-ff63ed3b4404",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
